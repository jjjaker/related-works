# related-works
# The following is the added literature review:
In recent years, numerous effective and novel feature selection methods have been proposed. Jinrui Gao introduced a hybrid algorithm called ISPSO, which combines Information Gain Ratio with Particle Swarm Optimization (PSO) for feature selection. By improving the initialization process and search strategy, ISPSO can more effectively assess the importance of features and enhance the algorithm's performance on feature selection problems [1]. Behrouz Ahadzadeh proposed a feature selection algorithm called SFE (Simple, Fast, Efficient), designed for high-dimensional datasets. This algorithm, through exploration and exploitation in two stages using non-selection and selection operations, sifts through features in high-dimensional datasets to identify those significantly impacting classification outcomes. Additionally, a hybrid algorithm called SFE-PSO (Particle Swarm Optimization) is introduced to find the optimal feature subset, thereby enhancing the efficiency and effectiveness of the algorithm. Experimental results demonstrate that both the SFE and SFE-PSO algorithms outperform six other recently proposed feature selection algorithms on 40 high-dimensional datasets [2]. Behrouz Ahadzadeh introduced a novel feature selection method called BDE-BSS-DR, which leverages Binary Differential Evolution (BDE), Binary Random Search (BSS) algorithm, and Dimensionality Reduction (DR) mechanism. BSS algorithm enhances BDE's search capability by escaping local optima and exploring the search space. Subsequently, the DR mechanism gradually reduces the dimensionality of the search space. The use of DR addresses issues such as local optima in the search space and erroneous removal of important features before the start of the search process [3]. Yinglan Feng proposed a feature selection algorithm based on EMT (Enhanced Multi-Tasking), aiming to address multi-objective high-dimensional classification problems. The algorithm first constructs the MO-FSEMT framework by generating relevant FS tasks, employing independent populations for multi-task optimization design, and incorporating a knowledge transfer mechanism based on task-specific advantages [4]. H. Saadatmand proposed an evolutionary algorithm based on integer encoding and fuzzy granulation for high-dimensional feature selection. This method enhances the transparency of the search process by employing set operations such as union, intersection, and complement for crossover and mutation operations. Additionally, utilizing fuzzy granulation as a repulsion strategy, it seeks differences during elitism and population initialization processes to achieve higher population diversity [5]. Jia-Quan Yang proposed a Particle Swarm Optimization (PSO) algorithm based on the Bi-Directional Feature Fixation (BDFF) framework, which guides the particle swarm to explore feature subsets of different sizes by setting two opposing search directions. BDFF fixes the selection status of certain features when updating particles, allowing focus on other features and effectively reducing the search space. Additionally, an adaptive strategy is introduced to guide the particle swarm towards more promising directions during different evolutionary stages, balancing exploration and exploitation. Experimental results on 12 public datasets demonstrate a significant enhancement in PSO's performance in large-scale feature selection, achieving smaller feature subsets with higher classification accuracy [6].
#[1]	Information gain ratio-based subfeature grouping empowers particle swarm optimization for feature selection
#[2]	SFE: A Simple, Fast, and Efficient Feature Selection Algorithm for High-Dimensional Data
#[3]	Improved binary differential evolution with dimensionality reduction mechanism and binary stochastic search for feature selection
#[4]	Towards Multi-Objective High-Dimensional Feature Selection via Evolutionary Multitasking
#[5]	Set-based integer-coded fuzzy granular evolutionary algorithms for high-dimensional feature selection.
#[6]	Bi-Directional Feature Fixation-Based Particle Swarm Optimization for Large-Scale Feature Selection
